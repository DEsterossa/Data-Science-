# Поиск токсичных комментариев

## Описание проекта
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

## Навыки и инструменты
<img src="https://img.shields.io/badge/Pandas-black?style=flat-square&logo=pandas&logoColor=orange"/><img src="https://img.shields.io/badge/Plotly-black?style=flat-square&logo=plotly&logoColor=orange"/><img src="https://img.shields.io/badge/Hugging_Face-black?style=flat-square&logo=huggingface&logoColor=orange"/><img src="https://img.shields.io/badge/Sklearn-black?logo=scikitlearn&logoColor=orange"><img src="https://img.shields.io/badge/BERT-black?style=flat-square&logo=google&logoColor=orange"/>

## Сферы деятельности:
Обработка и анализ данных, Машинное обучение, NLP

## Основные пункты исследования:
1. Заргрузка данных и их подготовка
2. Обучение модели с ТF-IDF
3. Обучение модели с Hugging Face
4. Использование предобученной модели
5. Анализ моделей
6. Общий вывод

## Выводы и результаты
В ходе исследования был проведен всесторонний анализ собранных комментариев, на основе которого были разработаны и протестированы четыре архитектуры моделей для выявления токсичного контента. Наилучшая из разработанных моделей продемонстрировала высокую эффективность, достигнув показателя F1-score в 78%, что свидетельствует о надежном балансе между точностью и полнотой классификации.
