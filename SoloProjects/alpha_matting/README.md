# Alpha Matting (ecom.tech / Kaggle): предсказание alpha-маски по RGB

![Python](https://img.shields.io/badge/Python-3.x-blue?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-2.x-red?style=for-the-badge&logo=pytorch)
![OpenCV](https://img.shields.io/badge/OpenCV-CV2-green?style=for-the-badge&logo=opencv)

## Описание проекта

Проект решает задачу **alpha matting**: по RGB-изображению фиксированного размера (1024×1024) предсказать **alpha-маску** (один канал, полутона 0…255) и минимизировать **MSE** на скрытом тесте соревнования.

Цель — не просто бинарная сегментация «объект/фон», а **плотная маска** с мягкими краями и полутонами внутри объекта. Такие системы нужны для:

- **Выделения объектов с мягкими границами** (волосы, мех, прозрачность) в редакторах и сервисах.
- **Подготовки контента для композитинга** и замены фона без «жёсткой» обрезки.
- **Задач компьютерного зрения**, где важна точность в полутонах (маттинг, green screen, портретная сегментация).

Цепочка пайплайна: **данные → модель U²-Net → инференс → (clamp [0..1]) → uint8 [0..255] → PNG → base64 → submission CSV**.

## Навыки и инструменты

**Сферы деятельности:**
Computer Vision, Alpha Matting, Semantic Segmentation, U²-Net, Transfer Learning, воспроизводимые эксперименты (CONFIG, seed).

**Инструменты:** PyTorch, Pandas, NumPy, OpenCV (cv2), PIL (Pillow), SciPy, Matplotlib, tqdm.

**Ключевые этапы разработки:**
*   **Подготовка данных:** кастомный `Dataset` для задачи маттинга (пары RGB + alpha), разметка в CSV (`image_path`, `alpha_path`), сплиты train/val. Использование датасета MAGICK с учётом того, что его alpha часто почти бинарная, в отличие от целевой метрики MSE на плотных масках.
*   **Аугментация alpha:** конвейер **xray_alpha_dense** на базе OpenCV: преобразование «жёсткой» alpha (0/255) в плотную — низкочастотная компонента по яркости, multi-scale DoG для текстуры внутри объекта, мягкий фон и полутона. Цель — сократить разрыв между обучающими данными и ожидаемым распределением alpha на скрытом тесте Kaggle.
*   **Модель:** архитектура **U²-Net (U2NETP)** с backbone для предсказания alpha в один канал. Загрузка предобученных весов `u2netp.pth`, дообучение на своих данных. Все параметры (пути, размеры, batch size, число эпох) вынесены в CONFIG для воспроизводимости.
*   **Loss и метрика:** составной **MSE-подобный loss** — базовый MSE по предсказанию, усиление по тонким деталям (thin_map), штраф за фон, взвешенный MSE по градиентам GT внутри объекта. Метрика мониторинга — **MSE** по главному выходу (d0), в соответствии с оценкой на Kaggle.
*   **Обучение и инференс:** обучение с сохранением лучшего чекпоинта по val MSE, снижение learning rate по val MSE. Инференс на тесте 1024×1024 (с TTA flip при необходимости), преобразование выхода в uint8 [0..255], кодирование PNG в base64 и сбор **submission.csv** с колонками `filename` и `image_utf`.

## Выводы и результаты

В ходе проекта собран полный пайплайн: от подготовки данных (CSV, кастомный Dataset) и аугментации плотных alpha-масок до обучения U2NETP и формирования submission в формате соревнования. Модель обучается минимизировать MSE, на валидации достигается val_mse порядка ~0.11–0.12 после 12 эпох с сохранением лучшего чекпоинта.

Разработанный пайплайн позволяет воспроизводимо проводить эксперименты (CONFIG, seed), визуализировать предсказания и анализировать влияние аугментаций и потерь на качество масок. Для дальнейшего улучшения MSE на Kaggle имеет смысл расширять данные с «мягкой» alpha, вводить proxy-метрики на синтетическом тесте и аккуратно подбирать постобработку, чтобы не ухудшать MSE при улучшении визуала.

---

**Как запустить:** откройте ноутбук `matting.ipynb`, задайте пути к данным в CONFIG (train/val CSV, папка теста, каталог для чекпоинтов и submission). Веса U2NETP положите в `U-2-Net/saved_models/u2netp/u2netp.pth` (источник — репозиторий U²-Net или инструкции соревнования). Зависимости: PyTorch, torchvision, pandas, numpy, opencv-python, Pillow, scipy, matplotlib, tqdm.
